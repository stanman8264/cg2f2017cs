@article{Konrad:2017:ACN:3072959.3073594,
 author = {Konrad, Robert and Padmanaban, Nitish and Molner, Keenan and Cooper, Emily A. and Wetzstein, Gordon},
 title = {Accommodation-invariant Computational Near-eye Displays},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {88:1--88:12},
 articleno = {88},
 numpages = {12},
 url = {http://doi.acm.org.umasslowell.idm.oclc.org/10.1145/3072959.3073594},
 doi = {10.1145/3072959.3073594},
 acmid = {3073594},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational displays, vergence-accommodation conflict},
 abstract = {Although emerging virtual and augmented reality (VR/AR) systems can produce highly immersive experiences, they can also cause visual discomfort, eyestrain, and nausea. One of the sources of these symptoms is a mismatch between vergence and focus cues. In current VR/AR near-eye displays, a stereoscopic image pair drives the vergence state of the human visual system to arbitrary distances, but the accommodation, or focus, state of the eyes is optically driven towards a fixed distance. In this work, we introduce a new display technology, dubbed accommodation-invariant (AI) near-eye displays, to improve the consistency of depth cues in near-eye displays. Rather than producing correct focus cues, AI displays are optically engineered to produce visual stimuli that are invariant to the accommodation state of the eye. The accommodation system can then be driven by stereoscopic cues, and the mismatch between vergence and accommodation state of the eyes is significantly reduced. We validate the principle of operation of AI displays using a prototype display that allows for the accommodation state of users to be measured while they view visual stimuli using multiple different display modes.},
 summary = {VR systems currently face problems due to the vergence-accommodation conflict.  One potential way to resolve this is to create an accommodation invariant display.  To do this, the authors of this paper create a display using a tunable lense that performs a continuous focal sweep.  The user perceptually integrates the sweep due to the finite exposure time of the human visual system.  To form a set of discrete steps, the LCD backlight is modulated at a frequency orders of magnitude faster than the refresh rate.  The user will accommodate to the version of the image that matches the vergence cues in the screen, thus reducing the vergence-accommodation conflict.  The focal sweep reduces effective resolution however, so deconvolution is used to attempt to regain clarity.  The results of a user study shows that accommodation response is greater than a fixed focal plane image, but less than a dynamic adjusted focal image.  The AI disaplay also shows significant loss of clarity when compared to a conventional fixed focus display which is in focus.  The AI displays shows an overall compromise across several metrics used to evaluate head mounted displays.  Hopefully future research will be albe to discover new deconvolution functions or use higher refresh rate displays to achieve a greate accommodation response as well as higher resoltion.},
} 