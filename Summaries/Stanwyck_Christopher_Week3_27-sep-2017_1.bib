@article{Arabadzhiyska:2017:SLP:3072959.3073642,
 author = {Arabadzhiyska, Elena and Tursun, Okan Tarhan and Myszkowski, Karol and Seidel, Hans-Peter and Didyk, Piotr},
 title = {Saccade Landing Position Prediction for Gaze-contingent Rendering},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {50:1--50:12},
 articleno = {50},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3072959.3073642},
 doi = {10.1145/3072959.3073642},
 acmid = {3073642},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {gaze-contingent rendering, new display technology, perception, saccade prediction, saccadic suppression, virtual reality},
abstract = {Gaze-contingent rendering shows promise in improving perceived quality by providing a better match between image quality and the human visual system requirements. For example, information about fixation allows rendering quality to be reduced in peripheral vision, and the additional resources can be used to improve the quality in the foveal region. Gaze-contingent rendering can also be used to compensate for certain limitations of display devices, such as reduced dynamic range or lack of accommodation cues. Despite this potential and the recent drop in the prices of eye trackers, the adoption of such solutions is hampered by system latency which leads to a mismatch between image quality and the actual gaze location. This is especially apparent during fast saccadic movements when the information about gaze location is significantly delayed, and the quality mismatch can be noticed. To address this problem, we suggest a new way of updating images in gaze-contingent rendering during saccades. Instead of rendering according to the current gaze position, our technique predicts where the saccade is likely to end and provides an image for the new fixation location as soon as the prediction is available. While the quality mismatch during the saccade remains unnoticed due to saccadic suppression, a correct image for the new fixation is provided before the fixation is established. This paper describes the derivation of a model for predicting saccade landing positions and demonstrates how it can be used in the context of gaze-contingent rendering to reduce the influence of system latency on the perceived quality. The technique is validated in a series of experiments for various combinations of display frame rate and eye-tracker sampling rate. },
 summary = { Gaze-contingent rendering is a promising technique which focuses rendering quality on foveal regions of the human visual system while reducing quality in the peripheral regions to achieve higher perceived rendering quality as well as higher performance rendering.  Eye tracking software can be used in this system to determine where the user’s gaze is focused so that rendering quality can be directed to that region.  Current systems introduce latency which can result in undesirable viewing experiences.  This paper introduces a technique which takes advantage of the properties of saccades, or quick eye movements, to predict where a user’s gaze will end up.  The goal is to reduce the latency between the updated perceived foveal region and the actual location of the user’s gaze.  The authors use a ballistic saccade model, data from test subjects, and calculated threshold velocities to predict the amplitude and direction of saccade movements to predict the landing location.  Part of what makes this technique work so well is saccadic suppression which means that during a saccade new visual information is highly compressed and thus keeping up with a saccade is less important than meeting the eye’s gaze at the end.  Limitations of this technique include the variability of saccades both within a subject and across subjects and the inability to correctly predict saccades for users with strong corrective glasses.  },

} 
