@article{Mehta:2017:VRH:3072959.3073596,
 author = {Mehta, Dushyant and Sridhar, Srinath and Sotnychenko, Oleksandr and Rhodin, Helge and Shafiei, Mohammad and Seidel, Hans-Peter and Xu, Weipeng and Casas, Dan and Theobalt, Christian},
 title = {VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {44:1--44:14},
 articleno = {44},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3072959.3073596},
 doi = {10.1145/3072959.3073596},
 acmid = {3073596},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {body pose, monocular, real time},
 abstract = {We present the first real-time method to capture the full global 3D skeletal pose of a human in a stable, temporally consistent manner using a single RGB camera. Our method combines a new convolutional neural network (CNN) based pose regressor with kinematic skeleton fitting. Our novel fully-convolutional pose formulation regresses 2D and 3D joint positions jointly in real time and does not require tightly cropped input frames. A real-time kinematic skeleton fitting method uses the CNN output to yield temporally stable 3D global pose reconstructions on the basis of a coherent kinematic skeleton. This makes our approach the first monocular RGB method usable in real-time applications such as 3D character control---thus far, the only monocular methods for such applications employed specialized RGB-D cameras. Our method's accuracy is quantitatively on par with the best offline 3D monocular RGB pose estimation methods. Our results are qualitatively comparable to, and sometimes better than, results from monocular RGB-D approaches, such as the Kinect. However, we show that our approach is more broadly applicable than RGB-D solutions, i.e., it works for outdoor scenes, community videos, and low quality commodity RGB cameras.},
 summary = { The authors of this paper introduce a motion capture technique which does not require multiple cameras or additional sensor information to create a stick figure model with 3-D coordinates.  The processing of this information is enabled in real-time at 30 Hz with sufficient processing power either locally or though streaming of video data to a capable machine.  This new technique is comparable in accuracy to existing offline techniques (not real-time) and real-time techniques which require additional sensor information to create depth information.  Its lower performance and sensor requirements allow commodity cameras such as cell phone cameras to become motion capture devices.  The algorithm uses a Convolutional Neural Network trained with a set of data of human poses along with kinematic skeleton fitting of the resultant pose predictions to create models with sufficient accuracy and temporal stability to be used in real time applications such as virtual reality, gaming and character control, or community videos.},
} 
