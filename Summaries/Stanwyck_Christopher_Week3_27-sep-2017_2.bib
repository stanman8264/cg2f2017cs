@article{Li:2017:MSA:3072959.3073641,
 author = {Li, Xiao and Dong, Yue and Peers, Pieter and Tong, Xin},
 title = {Modeling Surface Appearance from a Single Photograph Using Self-augmented Convolutional Neural Networks},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2017},
 volume = {36},
 number = {4},
 month = jul,
 year = {2017},
 issn = {0730-0301},
 pages = {45:1--45:11},
 articleno = {45},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/3072959.3073641},
 doi = {10.1145/3072959.3073641},
 acmid = {3073641},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CNN, SVBRDF, appearance modeling},
 abstract = {We present a convolutional neural network (CNN) based solution for modeling physically plausible spatially varying surface reflectance functions (SVBRDF) from a single photograph of a planar material sample under unknown natural illumination. Gathering a sufficiently large set of labeled training pairs consisting of photographs of SVBRDF samples and corresponding reflectance parameters, is a difficult and arduous process. To reduce the amount of required labeled training data, we propose to leverage the appearance information embedded in unlabeled images of spatially varying materials to self-augment the training process. Starting from an initial approximative network obtained from a small set of labeled training pairs, we estimate provisional model parameters for each unlabeled training exemplar. Given this provisional reflectance estimate, we then synthesize a novel temporary labeled training pair by rendering the exact corresponding image under a new lighting condition. After refining the network using these additional training samples, we re-estimate the provisional model parameters for the unlabeled data and repeat the self-augmentation process until convergence. We demonstrate the efficacy of the proposed network structure on spatially varying wood, metals, and plastics, as well as thoroughly validate the effectiveness of the self-augmentation training process.},
 summary = { Obtaining a reflectance map in the form of a SVBRDF from a single photograph with unknown lighting is desirable for creating plausible textures for virtual worlds.  This capability can replace traditional artistry with synthesized images based on a single photograph, much like a real artist would do.  The authors use a Convolutional Neural Nework with a small set of training data of the desired surface type.  They introduce a novel method to augment the CNN.   The input photograph is used to generate predicted model parameters.  Then, the parameters are used to synthesize a new input with different lighting parameters.  This process is repeated until there are enough training pairs to converge the network.  This method proves that they can successfully interpolate missing data over an incomplete dataset to create a fully trained network.  Limitations of the techniques in this paper are that the input images are required to be planar, the CNN training data itself must match the expected material, and the input photograph must exhibit all expected reflectance features.  Additionally, the specular component must be homogeneous.},
} 
